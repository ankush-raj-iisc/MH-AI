{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import PyPDF2\n",
    "import os\n",
    "import tempfile\n",
    "import json\n",
    "import re\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium import webdriver\n",
    "\n",
    "path='.\\chromedriver.exe'\n",
    "# set up the webdriver\n",
    "driver = webdriver.Chrome(path)\n",
    "driver.maximize_window()\n",
    "pageNum=0\n",
    "webpage='''https://indiankanoon.org/search/?formInput=insider%20trading%20%20%20doctypes%3A%20supremecourt%2Cscorders%2Chighcourts&pagenum={}'''.format(pageNum)\n",
    "# navigate to the webpage\n",
    "driver.get(webpage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import PyPDF2\n",
    "import os\n",
    "import tempfile\n",
    "import json\n",
    "import re\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium import webdriver\n",
    "\n",
    "path = '.\\\\chromedriver.exe'  # Corrected the path separator\n",
    "\n",
    "# set up the webdriver\n",
    "driver = webdriver.Chrome(path)\n",
    "driver.maximize_window()\n",
    "pageNum = 0\n",
    "links = {}\n",
    "\n",
    "while pageNum<40:\n",
    "    webpage = 'https://indiankanoon.org/search/?formInput=insider%20trading%20%20%20doctypes%3A%20supremecourt%2Cscorders%2Chighcourts&pagenum={}'.format(pageNum)\n",
    "\n",
    "    # navigate to the webpage\n",
    "    driver.get(webpage)\n",
    "\n",
    "    # find the element with xpath = /html/body/div[2]/div[3]/div[2]/div[1]/a\n",
    "    a_element = driver.find_element(By.XPATH, '/html/body/div[2]/div[3]/div[2]/div[1]/a')  # Corrected the find_element syntax\n",
    "\n",
    "    # get the text and href link of the element\n",
    "    text = a_element.text\n",
    "    link = a_element.get_attribute('href')\n",
    "\n",
    "    # add the text and href link to the python dict named links\n",
    "    links[text] = link\n",
    "\n",
    "    try:\n",
    "        # get the next page number\n",
    "        next_page_element = driver.find_element(By.XPATH, '//*[@id=\"pagination\"]/ul/li[last()]/a')  # Corrected the find_element syntax\n",
    "        next_page_number = next_page_element.text\n",
    "\n",
    "        # if the next page number is not empty, then go to the next page\n",
    "        if next_page_number:\n",
    "            pageNum = int(next_page_number)\n",
    "        else:\n",
    "            break\n",
    "    except NoSuchElementException:\n",
    "        break\n",
    "    pageNum=pageNum+1\n",
    "\n",
    "# print the links\n",
    "print(links)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### the below code is working fine for only one page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the webdriver\n",
    "driver = webdriver.Chrome(path)\n",
    "driver.maximize_window()\n",
    "pageNum = 0\n",
    "links = {}\n",
    "\n",
    "while pageNum < 40:\n",
    "    webpage = 'https://indiankanoon.org/search/?formInput=insider%20trading%20%20%20doctypes%3A%20supremecourt%2Cscorders%2Chighcourts&pagenum={}'.format(pageNum)\n",
    "\n",
    "    # navigate to the webpage\n",
    "    driver.get(webpage)\n",
    "\n",
    "    # find all link elements with class name \"result\"\n",
    "    link_elements = driver.find_elements(By.CLASS_NAME, 'result')\n",
    "\n",
    "    # iterate over each link element\n",
    "    for element in link_elements:\n",
    "        # find the link element within the parent container\n",
    "        link_element = element.find_element(By.TAG_NAME, 'a')\n",
    "        \n",
    "        # get the text and href link of the element\n",
    "        text = link_element.text\n",
    "        link = link_element.get_attribute('href')\n",
    "\n",
    "        # add the text and href link to the python dict named links\n",
    "        links[text] = link\n",
    "\n",
    "    try:\n",
    "        # get the next page number\n",
    "        next_page_element = driver.find_element(By.XPATH, '//*[@id=\"pagination\"]/ul/li[last()]/a')\n",
    "        next_page_number = next_page_element.text\n",
    "\n",
    "        # if the next page number is not empty, then go to the next page\n",
    "        if next_page_number:\n",
    "            pageNum = int(next_page_number)\n",
    "        else:\n",
    "            break\n",
    "    except NoSuchElementException:\n",
    "        break\n",
    "    pageNum += 1\n",
    "\n",
    "# print the links\n",
    "print(links)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the webdriver\n",
    "driver = webdriver.Chrome(path)\n",
    "driver.maximize_window()\n",
    "pageNum = 0\n",
    "links = {}\n",
    "\n",
    "while pageNum < 40:\n",
    "    webpage = 'https://indiankanoon.org/search/?formInput=insider%20trading%20%20%20doctypes%3A%20supremecourt%2Cscorders%2Chighcourts&pagenum={}'.format(pageNum)\n",
    "    pageNum += 1\n",
    "\n",
    "    # navigate to the webpage\n",
    "    driver.get(webpage)\n",
    "\n",
    "    # find all link elements with class name \"result\"\n",
    "    link_elements = driver.find_elements(By.CLASS_NAME, 'result')\n",
    "\n",
    "    # iterate over each link element\n",
    "    for element in link_elements:\n",
    "        # find the link element within the parent container\n",
    "        link_element = element.find_element(By.TAG_NAME, 'a')\n",
    "        \n",
    "        # get the text and href link of the element\n",
    "        text = link_element.text\n",
    "        link = link_element.get_attribute('href')\n",
    "\n",
    "        # add the text and href link to the python dict named links\n",
    "        links[text] = link\n",
    "\n",
    "        \n",
    "        # next_button = driver.find_element(By.XPATH,\"/html/body/div[2]/div[3]/div[13]/a[2]\")\n",
    "        # next_button.click()\n",
    "    nextPage=webpage = '''https://indiankanoon.org/search/?formInput=insider%20trading%20%20%20doctypes%3A%20supremecourt%2Cscorders%2Chighcourts&pagenum={}'''.format(pageNum)\n",
    "    driver.get(nextPage)\n",
    "\n",
    "\n",
    "    # try:\n",
    "    #     # get the next page number\n",
    "    #     next_page_element = driver.find_element(By.XPATH, '//*[@id=\"pagination\"]/ul/li[last()]/a')\n",
    "    #     next_page_number = next_page_element.get_attribute('innerHTML')  # Retrieve the value from innerHTML attribute\n",
    "\n",
    "    #     # if the next page number is not empty, then go to the next page\n",
    "    #     if next_page_number:\n",
    "    #         pageNum = int(next_page_number)\n",
    "    #     else:\n",
    "    #         break\n",
    "    # except NoSuchElementException:\n",
    "    #     break\n",
    "    \n",
    "\n",
    "# print the links\n",
    "print(links)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Assuming you have the 'links' dictionary\n",
    "\n",
    "# Convert the dictionary to JSON format\n",
    "json_data = json.dumps(links, indent=4)\n",
    "\n",
    "# Specify the file path to save the JSON data\n",
    "file_path = 'rough_links.json'\n",
    "\n",
    "# Write the JSON data to the file\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json_file.write(json_data)\n",
    "\n",
    "print(\"Links saved to links.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Set up the Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')  # Run Chrome in headless mode\n",
    "\n",
    "# Set up the webdriver\n",
    "driver = webdriver.Chrome(path, options=chrome_options)\n",
    "driver.maximize_window()\n",
    "pageNum = 0\n",
    "links = {}\n",
    "\n",
    "# Set up the WebDriverWait with a timeout of 10 seconds\n",
    "wait = WebDriverWait(driver, 10)\n",
    "\n",
    "while pageNum < 40:\n",
    "    webpage = 'https://indiankanoon.org/search/?formInput=insider%20trading%20%20%20doctypes%3A%20supremecourt%2Cscorders%2Chighcourts&pagenum={}'.format(pageNum)\n",
    "    pageNum += 1\n",
    "\n",
    "    # Navigate to the webpage\n",
    "    driver.get(webpage)\n",
    "\n",
    "    # Wait for the link elements with class name \"result\" to be present\n",
    "    link_elements = wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, 'result')))\n",
    "\n",
    "    # Iterate over each link element\n",
    "    for element in link_elements:\n",
    "        # Find the link element within the parent container\n",
    "        link_element = element.find_element(By.TAG_NAME, 'a')\n",
    "\n",
    "        # Get the text and href link of the element\n",
    "        text = link_element.text\n",
    "        link = link_element.get_attribute('href')\n",
    "\n",
    "        # Add the text and href link to the Python dict named links\n",
    "        links[text] = link\n",
    "\n",
    "    # Print the links\n",
    "    print(links)\n",
    "\n",
    "    # Proceed to the next page by updating the webpage URL\n",
    "    nextPage = 'https://indiankanoon.org/search/?formInput=insider%20trading%20%20%20doctypes%3A%20supremecourt%2Cscorders%2Chighcourts&pagenum={}'.format(pageNum)\n",
    "    driver.get(nextPage)\n",
    "\n",
    "# Print the final links\n",
    "print(links)\n",
    "print(len(links))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Assuming you have the 'links' dictionary\n",
    "\n",
    "# Convert the dictionary to JSON format\n",
    "json_data = json.dumps(links, indent=4)\n",
    "\n",
    "# Specify the file path to save the JSON data\n",
    "file_path = 'rough_links.json'\n",
    "\n",
    "# Write the JSON data to the file\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json_file.write(json_data)\n",
    "\n",
    "print(\"Links saved to fair_links.json\")\n",
    "\n",
    "import pandas as pd\n",
    "df=pd.read_json(\"./rough_links.json\" , typ=\"series\")\n",
    "df\n",
    "df = df.apply(lambda x: x.replace(\"/docfragment/\", \"/doc/\").split(\"?\")[0])\n",
    "\n",
    "# Print the updated links\n",
    "print(df)\n",
    "df.to_csv(\"./fair_links.csv\")\n",
    "df.columns()\n",
    "df=pd.read_csv(\"./fair_links.csv\")\n",
    "df.columns = ['texts', 'links']\n",
    "df.columns\n",
    "df.head()\n",
    "df.to_csv('./fair_links.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set up the webdriver\n",
    "driver = webdriver.Chrome(path)\n",
    "driver.maximize_window()\n",
    "\n",
    "# Read the DataFrame from the CSV file\n",
    "df = pd.read_csv('./fair_links.csv')\n",
    "\n",
    "# Create an empty dictionary to store the results\n",
    "result_dict = {}\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    text = row['texts']\n",
    "    link = row['links']\n",
    "    \n",
    "    # Open the link\n",
    "    driver.get(link)\n",
    "    \n",
    "    # Find the elements on the webpage\n",
    "    judgements_element = driver.find_element(By.XPATH, '/html/body/div[9]')\n",
    "    doc_title_element = driver.find_element(By.CLASS_NAME, 'doc_title')\n",
    "    \n",
    "    # Get the text from the elements\n",
    "    judgements_text = judgements_element.text\n",
    "    doc_title_text = doc_title_element.text\n",
    "    \n",
    "    # Store the text in the dictionary\n",
    "    result_dict[text] = {\n",
    "        'judgements': judgements_text,\n",
    "        'doc_title': doc_title_text\n",
    "        #'doc_author': doc_author\n",
    "        #'bench': doc_bench\n",
    "\n",
    "        \n",
    "    }\n",
    "    #inside another dict put keyword:para mapping\n",
    "    print(result_dict)\n",
    "    \n",
    "# Print the result dictionary\n",
    "print(result_dict)\n",
    "\n",
    "# Close the webdriver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
